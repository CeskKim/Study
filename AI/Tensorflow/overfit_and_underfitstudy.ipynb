{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "overfit_and_underfitstudy.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES5YYGRawJGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모듈\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cw7UWKnxrke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 테스트 내역 주석처리\n",
        "# NUM_WORDS = 10000\n",
        "# # 학습데이터, 테스트데이터 설정\n",
        "# (train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkRvx5JJyjya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_WORDS = 10000\n",
        "# 학습데이터, 테스트데이터 설정(imbdb)\n",
        "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "# 멀티-핫-벡터 함수 설정\n",
        "def multi_hot_sequences(sequences, dimension):    \n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, word_indices in enumerate(sequences):\n",
        "        results[i, word_indices] = 1.0 \n",
        "    return results\n",
        "train_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)\n",
        "test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0u2pzqcz0qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습데이터 시각화 확인\n",
        "plt.plot(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khFFD0H10B2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 기준 모델 생성\n",
        "baseline_model = keras.Sequential([\n",
        "                                   keras.layers.Dense(16, activation='relu', input_shape=(NUM_WORDS,)),\n",
        "                                   keras.layers.Dense(16, activation='relu'),\n",
        "                                   keras.layers.Dense(1, activation='sigmoid')])\n",
        "baseline_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'binary_crossentropy']) #손실함수 : binary_crossentropy(2개분류), sparse_categorical_crossentropy(3개분류)\n",
        "baseline_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv__tV_22kwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 학습(기준모델)\n",
        "# RAM용량으로 인해 epochs -> 2 변경\n",
        "baseline_history = baseline_model.fit(train_data, train_labels, epochs=2, batch_size=512, validation_data=(test_data, test_labels), verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3QWqbrc4zTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 작은 모델\n",
        "smllaer_model = keras.Sequential([\n",
        "                                   keras.layers.Dense(4, activation='relu', input_shape=(NUM_WORDS,)),\n",
        "                                   keras.layers.Dense(4, activation='relu'),\n",
        "                                   keras.layers.Dense(1, activation='sigmoid')])\n",
        "smllaer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'binary_crossentropy'])\n",
        "smllaer_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTBEDDtM5CuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 학습(작은 모델)\n",
        "# RAM용량으로 인해 epochs -> 2, verbose -> 0 \n",
        "smllaer_history = smllaer_model.fit(train_data, train_labels, epochs=2, batch_size=512, validation_data=(test_data, test_labels), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAY2QPYW6H4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 큰 모델 \n",
        "bigger_model = keras.Sequential([\n",
        "                                   keras.layers.Dense(512, activation='relu', input_shape=(NUM_WORDS,)),\n",
        "                                   keras.layers.Dense(512, activation='relu'),\n",
        "                                   keras.layers.Dense(1, activation='sigmoid')])\n",
        "bigger_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'binary_crossentropy'])\n",
        "bigger_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfS9A4tB6j6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 학습(큰 모델)\n",
        "# RAM용량으로 인해 epochs -> 2, verbose -> 0 \n",
        "bigger_history = bigger_model.fit(train_data, train_labels, epochs=2, batch_size=512, validation_data=(test_data, test_labels), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuOk1DUp6xQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련손실, 검증 손실 그래프 시각화\n",
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    for name, history in histories:\n",
        "        val = plt.plot(history.epoch, history.history['val_' +key], '--', label=name.title()+'Val')\n",
        "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title()+'Train')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(key.replace('_','').title())\n",
        "    # 그래프별 라벨 설정\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlim([0, max(history.epoch)])\n",
        "     \n",
        "plot_history([('baseline', baseline_history),\n",
        "              ('smaller',smllaer_history),\n",
        "              ('bigger', bigger_history)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KhVJCBi-mK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l2정규화\n",
        "l2_model = keras.models.Sequential([\n",
        "                                    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu', input_shape=(NUM_WORDS,)),\n",
        "                                    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu', input_shape=(NUM_WORDS,)),\n",
        "                                    keras.layers.Dense(1, activation='sigmoid')])\n",
        "l2_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'binary_crossentropy'])\n",
        "l2_model_history = l2_model.fit(train_data, train_labels, epochs=2, batch_size=512, validation_data=(test_data, test_labels), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YpEXL4p_uyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history([('baseline', baseline_history),\n",
        "              ('l2',l2_model_history)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1LsFdYtAKDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 드롭 아웃 : 벡터의 원소중 랜덤하게 0으로 변환, 보통 0.2 ~ 0.5 사이 사용\n",
        "dpt_model = keras.models.Sequential([\n",
        "                                    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu', input_shape=(NUM_WORDS,)),\n",
        "                                    keras.layers.Dropout(0.5),\n",
        "                                    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu', input_shape=(NUM_WORDS,)),\n",
        "                                    keras.layers.Dropout(0.5),\n",
        "                                    keras.layers.Dense(1, activation='sigmoid')])                                    \n",
        "dpt_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'binary_crossentropy'])\n",
        "dpt_model_history = dpt_model.fit(train_data, train_labels, epochs=2, batch_size=512, validation_data=(test_data, test_labels), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esf-cBu3Axk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history([('baseline', baseline_history),\n",
        "              ('dropout',dpt_model_history)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}